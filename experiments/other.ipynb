{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripletNetwork(\n",
       "  (embedding_network): ConvolutionalNetwork(\n",
       "    (convolution_1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (convolution_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (convolution_3): Conv2d(16, 20, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (fully_connected_1): Linear(in_features=16820, out_features=15000, bias=True)\n",
       "    (fully_connected_2): Linear(in_features=15000, out_features=1200, bias=True)\n",
       "    (fully_connected_3): Linear(in_features=1200, out_features=125, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pickle, sys, torch\n",
    "\n",
    "from settings import ROOT_DIR\n",
    "\n",
    "resume = '19-05-08T20-18'\n",
    "start_epoch = 1\n",
    "\n",
    "checkpoint_directory = os.path.join(ROOT_DIR, 'static', 'checkpoints', 'triplet_cnn', resume)\n",
    "\n",
    "net = torch.load(os.path.join(checkpoint_directory, '_net_%s.pth' % start_epoch))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from src.datasets import get_dataset\n",
    "\n",
    "dataset_name = 'sketchy_test_photos_triplets'\n",
    "workers = 4\n",
    "collate = default_collate\n",
    "\n",
    "dataset = get_dataset(dataset_name)\n",
    "\n",
    "batch_size = int(len(dataset) / 2)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, collate_fn=collate\n",
    ")\n",
    "\n",
    "print(sys.getsizeof(dataset))\n",
    "print(sys.getsizeof(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(data_loader))\n",
    "\n",
    "query_image = real_batch[0][0]\n",
    "query_class = real_batch[0][1]\n",
    "\n",
    "print(sys.getsizeof(real_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors = net(real_batch)\n",
    "print(query_vectors.size())\n",
    "print(sys.getsizeof(query_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(mat, k):\n",
    "    mat = mat.float()\n",
    "    mat_square = torch.mm(mat, mat.t())\n",
    "    diag = torch.diagonal(mat_square)\n",
    "    diag = diag.expand_as(mat_square)\n",
    "    dist_mat = (diag + diag.t() - 2 * mat_square)\n",
    "    dist_col = dist_mat[-1, :-1]\n",
    "    # k+1 because the nearest must be itself\n",
    "    val, index = dist_col.topk(k, largest=False, sorted=True)\n",
    "    return val, index\n",
    "\n",
    "\n",
    "a = KNN(query_vectors, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
